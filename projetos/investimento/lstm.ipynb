{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from processador_ibovespa import ProcessadorIbovespa\n",
    "\n",
    "caminho_arquivo = \"../../dados/investimento/ibovespa.csv\"\n",
    "processador = ProcessadorIbovespa(caminho_arquivo)\n",
    "features_desejadas = ['dias_semana', 'lags', 'diffs', 'volatilidade', 'medias_moveis', 'nulos_tratados']\n",
    "\n",
    "df_final = processador.get_dataframe(features=features_desejadas)\n",
    "df_final.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import LSTM, Dense\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import numpy as np\n",
    "\n",
    "scaler = MinMaxScaler()\n",
    "df_scaled = scaler.fit_transform(df_final.drop(['Data'], axis=1))\n",
    "\n",
    "X = df_scaled[:, 1:]  \n",
    "y = df_scaled[:, 0]   \n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, shuffle=False)\n",
    "\n",
    "X_train = np.reshape(X_train, (X_train.shape[0], 1, X_train.shape[1]))\n",
    "X_test = np.reshape(X_test, (X_test.shape[0], 1, X_test.shape[1]))\n",
    "\n",
    "model = Sequential()\n",
    "model.add(LSTM(units=50, return_sequences=True, input_shape=(X_train.shape[1], X_train.shape[2])))\n",
    "model.add(LSTM(units=50))\n",
    "model.add(Dense(1))\n",
    "\n",
    "model.compile(optimizer='adam', loss='mean_squared_error')\n",
    "\n",
    "model.fit(X_train, y_train, epochs=100, batch_size=32)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Avaliando o modelo\n",
    "loss = model.evaluate(X_test, y_test)\n",
    "print(f\"Loss no Teste: {loss}\")\n",
    "\n",
    "# Previsões\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# Redimensionar y_pred para garantir a compatibilidade de forma\n",
    "y_pred = y_pred.reshape(-1)\n",
    "\n",
    "# Preparando dados para reverter a normalização (assumindo que 'Último' é a primeira coluna no scaler)\n",
    "y_pred_expanded = np.concatenate([y_pred.reshape(-1, 1), np.zeros((y_pred.shape[0], df_scaled.shape[1] - 1))], axis=1)\n",
    "y_test_expanded = np.concatenate([y_test.reshape(-1, 1), np.zeros((y_test.shape[0], df_scaled.shape[1] - 1))], axis=1)\n",
    "\n",
    "# Reverter a normalização para interpretar as previsões no espaço original\n",
    "y_pred_original = scaler.inverse_transform(y_pred_expanded)[:, 0]\n",
    "y_test_original = scaler.inverse_transform(y_test_expanded)[:, 0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Plotando valores reais vs previsões\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.plot(y_test_original, label='Valores Reais')\n",
    "plt.plot(y_pred_original, label='Previsões', alpha=0.7)\n",
    "plt.title('Valores Reais vs Previsões')\n",
    "plt.xlabel('Tempo')\n",
    "plt.ylabel('Valor')\n",
    "plt.legend()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_absolute_percentage_error\n",
    "\n",
    "# Calculando MAPE\n",
    "mape = mean_absolute_percentage_error(y_test_original, y_pred_original)\n",
    "print(f\"MAPE: {mape}\")\n",
    "\n",
    "# Calculando WMAPE\n",
    "wmape = np.sum(np.abs(y_test_original - y_pred_original)) / np.sum(y_test_original)\n",
    "print(f\"WMAPE: {wmape}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "residuos = y_test_original - y_pred_original\n",
    "\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.plot(residuos)\n",
    "plt.title('Resíduos das Previsões')\n",
    "plt.xlabel('Tempo')\n",
    "plt.ylabel('Resíduo')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "limite_aceitavel = 0.3  # 5% de erro\n",
    "acertos = np.sum(np.abs((y_pred_original - y_test_original) / y_test_original) < limite_aceitavel)\n",
    "acuracia = acertos / len(y_test_original)\n",
    "\n",
    "print(f\"Acurácia (com base em um limite de erro de {limite_aceitavel * 100}%): {acuracia * 100}%\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_squared_error\n",
    "import numpy as np\n",
    "\n",
    "# Função para calcular a importância de permutação\n",
    "def permutation_importance(model, X, y, metric):\n",
    "    baseline_score = metric(y, model.predict(X))\n",
    "    importance = {}\n",
    "    for i in range(X.shape[2]):  # X.shape[2] é o número de features\n",
    "        X_permuted = X.copy()\n",
    "        np.random.shuffle(X_permuted[:, :, i])  # Embaralhar a feature i\n",
    "        permuted_score = metric(y, model.predict(X_permuted))\n",
    "        importance[i] = baseline_score - permuted_score  # Diferença no desempenho\n",
    "    return importance\n",
    "\n",
    "# Redimensionando X_test para o formato do LSTM se necessário\n",
    "X_test_transformed = X_test.reshape((X_test.shape[0], 1, X_test.shape[1]))\n",
    "\n",
    "# Calculando a importância\n",
    "importance_scores = permutation_importance(wrapped_model, X_test_transformed, y_test, mean_squared_error)\n",
    "\n",
    "# Imprimindo a importância\n",
    "for i, score in importance_scores.items():\n",
    "    print(f\"Feature {i} - Score: {score}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "fiap-3.10.11",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
